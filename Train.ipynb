{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Импорт библиотек**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:10:55.237054Z",
     "end_time": "2023-04-24T20:10:55.254667Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from PreapreDataLib import create_folder_if_not_exists\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from mmengine.config import *\n",
    "from mmengine.runner import set_random_seed\n",
    "from mmdet.datasets import CocoDataset\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmengine.registry import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.abspath('./DatasetCocoFormat/')\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "TEST_DIR  = os.path.join(DATASET_DIR, 'test')\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'val')\n",
    "ANN_DIR = os.path.join(DATASET_DIR, 'annotations')\n",
    "TRAIN_ANN_PTH = os.path.join(ANN_DIR, \"train.json\")\n",
    "VAL_ANN_PTH = os.path.join(ANN_DIR, \"val.json\")\n",
    "TEST_ANN_PTH = os.path.join(ANN_DIR, \"test.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T18:08:09.702014Z",
     "end_time": "2023-04-24T18:08:09.709020Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Загрузка конфига Mask R-CNN ResNet101 FPN 1x**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "CONFIGS_DIR = os.path.abspath(\"./configs\")\n",
    "create_folder_if_not_exists(\"./configs\")\n",
    "MRCNN_BASE_CONFIG_PTH = os.path.join(CONFIGS_DIR, \"mask-rcnn_r101_fpn_1x_coco.py\")\n",
    "MRCNN_USER_CONFIG_PTH = os.path.join(CONFIGS_DIR, \"mask-rcnn_r101_fpn_1x_coco_for_road_damages.py\")\n",
    "if not os.path.exists(MRCNN_BASE_CONFIG_PTH):\n",
    "    !mim download mmdet --config mask-rcnn_r101_fpn_1x_coco --dest \"./configs\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:47:31.973712Z",
     "end_time": "2023-04-24T20:47:31.981490Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Изменение конфига под задачу и датасет**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    data_preprocessor=dict(\n",
      "        type='DetDataPreprocessor',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32),\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained',\n",
      "                      checkpoint='torchvision://resnet101')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=3,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=3,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat'\n",
      "backend_args = None\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='Resize', scale=(1280, 640), keep_ratio=True),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PackDetInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='Resize', scale=(1280, 640), keep_ratio=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        type='PackDetInputs',\n",
      "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                   'scale_factor'))\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat',\n",
      "        ann_file=\n",
      "        'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat\\\\annotations\\\\train.json',\n",
      "        data_prefix=dict(img='train/'),\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='Resize', scale=(1280, 640), keep_ratio=True),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PackDetInputs')\n",
      "        ],\n",
      "        backend_args=None))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat',\n",
      "        ann_file=\n",
      "        'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat\\\\annotations\\\\val.json',\n",
      "        data_prefix=dict(img='val/'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(1280, 640), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                           'scale_factor'))\n",
      "        ],\n",
      "        backend_args=None))\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat',\n",
      "        ann_file=\n",
      "        'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat\\\\annotations\\\\test.json',\n",
      "        data_prefix=dict(img='test/'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(1280, 640), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                           'scale_factor'))\n",
      "        ],\n",
      "        backend_args=None))\n",
      "val_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat\\\\annotations\\\\val.json',\n",
      "    metric=['bbox', 'segm'],\n",
      "    format_only=False,\n",
      "    backend_args=None)\n",
      "test_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    'D:\\\\University\\\\RoadDamageDetection\\\\DatasetCocoFormat\\\\annotations\\\\test.json',\n",
      "    metric=['bbox', 'segm'],\n",
      "    format_only=False,\n",
      "    backend_args=None)\n",
      "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=1)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
      "    dict(\n",
      "        type='MultiStepLR',\n",
      "        begin=0,\n",
      "        end=12,\n",
      "        by_epoch=True,\n",
      "        milestones=[8, 11],\n",
      "        gamma=0.1)\n",
      "]\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001))\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "default_scope = 'mmdet'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=50),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[dict(type='LocalVisBackend')],\n",
      "    name='visualizer')\n",
      "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(MRCNN_BASE_CONFIG_PTH)\n",
    "\n",
    "cfg[\"model\"][\"roi_head\"][\"bbox_head\"][\"num_classes\"] = 3\n",
    "cfg[\"model\"][\"roi_head\"][\"mask_head\"][\"num_classes\"] = 3\n",
    "\n",
    "cfg[\"data_root\"] = DATASET_DIR\n",
    "\n",
    "cfg[\"train_dataloader\"][\"batch_size\"] = 1\n",
    "cfg[\"val_dataloader\"][\"batch_size\"] = 1\n",
    "cfg[\"test_dataloader\"][\"batch_size\"] = 1\n",
    "\n",
    "cfg[\"train_dataloader\"][\"num_workers\"] = 1\n",
    "cfg[\"val_dataloader\"][\"num_workers\"] = 1\n",
    "cfg[\"test_dataloader\"][\"num_workers\"] = 1\n",
    "\n",
    "cfg[\"train_dataloader\"][\"dataset\"][\"data_root\"] = DATASET_DIR\n",
    "cfg[\"val_dataloader\"][\"dataset\"][\"data_root\"] = DATASET_DIR\n",
    "cfg[\"test_dataloader\"][\"dataset\"][\"data_root\"] = DATASET_DIR\n",
    "\n",
    "cfg[\"train_dataloader\"][\"dataset\"][\"data_prefix\"][\"img\"] = \"train/\"\n",
    "cfg[\"val_dataloader\"][\"dataset\"][\"data_prefix\"][\"img\"] = \"val/\"\n",
    "cfg[\"test_dataloader\"][\"dataset\"][\"data_prefix\"][\"img\"] = \"test/\"\n",
    "\n",
    "cfg[\"train_dataloader\"][\"dataset\"][\"ann_file\"] = TRAIN_ANN_PTH\n",
    "cfg[\"val_dataloader\"][\"dataset\"][\"ann_file\"] = VAL_ANN_PTH\n",
    "cfg[\"test_dataloader\"][\"dataset\"][\"ann_file\"] = TEST_ANN_PTH\n",
    "\n",
    "cfg[\"val_evaluator\"][\"ann_file\"] = VAL_ANN_PTH\n",
    "cfg[\"test_evaluator\"][\"ann_file\"] = TEST_ANN_PTH\n",
    "\n",
    "cfg[\"test_pipeline\"][1][\"scale\"] = (1280, 640)\n",
    "cfg[\"train_pipeline\"][2][\"scale\"] = (1280, 640)\n",
    "\n",
    "cfg[\"train_dataloader\"][\"dataset\"][\"pipeline\"][2][\"scale\"] = (1280, 640)\n",
    "cfg[\"val_dataloader\"][\"dataset\"][\"pipeline\"][1][\"scale\"] = (1280, 640)\n",
    "cfg[\"test_dataloader\"][\"dataset\"][\"pipeline\"][1][\"scale\"] = (1280, 640)\n",
    "\n",
    "if os.path.exists(MRCNN_USER_CONFIG_PTH):\n",
    "    os.remove(MRCNN_USER_CONFIG_PTH)\n",
    "cfg.dump(MRCNN_USER_CONFIG_PTH)\n",
    "\n",
    "user_config = Config.fromfile(MRCNN_USER_CONFIG_PTH)\n",
    "print(user_config.pretty_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:47:54.939136Z",
     "end_time": "2023-04-24T20:47:57.573015Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
