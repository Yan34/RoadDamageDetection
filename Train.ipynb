{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Импорт библиотек**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:44:36.014499Z",
     "end_time": "2023-04-25T16:44:40.843949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\University\\miniconda3\\envs\\RoadDamageDetection\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from PreapreDataLib import create_folder_if_not_exists\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector, init_detector, inference_detector\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_DIR = './DatasetCocoFormat/'\n",
    "TRAIN_DIR = DATASET_DIR + 'train/'\n",
    "TEST_DIR  = DATASET_DIR + 'test/'\n",
    "VAL_DIR = DATASET_DIR + 'val/'\n",
    "ANN_DIR = DATASET_DIR + 'annotations/'\n",
    "TRAIN_ANN_PTH = ANN_DIR + \"train.json\"\n",
    "VAL_ANN_PTH = ANN_DIR + \"val.json\"\n",
    "TEST_ANN_PTH = ANN_DIR + \"test.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:44:40.844950Z",
     "end_time": "2023-04-25T16:44:40.860009Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Загрузка конфига Mask R-CNN ResNet101 FPN 1x**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CONFIGS_DIR = \"./configs/\"\n",
    "create_folder_if_not_exists(\"./configs/\")\n",
    "MRCNN_BASE_CONFIG_PTH = CONFIGS_DIR + \"mask_rcnn_r50_fpn_1x_coco.py\"\n",
    "MRCNN_USER_CONFIG_PTH = CONFIGS_DIR + \"mask_rcnn_r50_fpn_1x_coco_for_road_damages.py\"\n",
    "if not os.path.exists(MRCNN_BASE_CONFIG_PTH):\n",
    "    !mim download mmdet --config mask_rcnn_r50_fpn_1x_coco --dest \"./configs\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:44:40.860009Z",
     "end_time": "2023-04-25T16:44:40.877025Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Изменение конфига под задачу и датасет**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=3,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=3,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = './DatasetCocoFormat/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1333, 800),\n",
      "        keep_ratio=True,\n",
      "        scale=(894, 448)),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ],\n",
      "        scale=(894, 448))\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='./DatasetCocoFormat/annotations/train.json',\n",
      "        img_prefix='./DatasetCocoFormat/train/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='Resize', img_scale=(894, 448), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ],\n",
      "        classes=('lane', 'crack', 'pothole')),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='./DatasetCocoFormat/annotations/val.json',\n",
      "        img_prefix='./DatasetCocoFormat/val/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(894, 448),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('lane', 'crack', 'pothole')),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='./DatasetCocoFormat/annotations/test.json',\n",
      "        img_prefix='./DatasetCocoFormat/test/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(894, 448),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('lane', 'crack', 'pothole')))\n",
      "evaluation = dict(metric=['bbox', 'segm'])\n",
      "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "classes = ('lane', 'crack', 'pothole')\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "work_dir = './configs/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(MRCNN_BASE_CONFIG_PTH)\n",
    "\n",
    "# cfg.merge_from_dict(dict(classes = [\"lane\", \"crack\", \"pothole\"]))\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 3\n",
    "cfg.model.roi_head.mask_head.num_classes = 3\n",
    "\n",
    "cfg.data_root = DATASET_DIR\n",
    "\n",
    "cfg.data.samples_per_gpu = 1\n",
    "cfg.data.workers_per_gpu = 1\n",
    "\n",
    "cfg.data.train.img_prefix = TRAIN_DIR\n",
    "cfg.data.val.img_prefix = VAL_DIR\n",
    "cfg.data.test.img_prefix = TEST_DIR\n",
    "\n",
    "cfg.data.train.ann_file = TRAIN_ANN_PTH\n",
    "cfg.data.val.ann_file = VAL_ANN_PTH\n",
    "cfg.data.test.ann_file = TEST_ANN_PTH\n",
    "\n",
    "# (1280, 640)\n",
    "cfg.test_pipeline[1].scale = (894, 448)\n",
    "cfg.train_pipeline[2].scale = (894, 448)\n",
    "\n",
    "cfg.data.train.pipeline[2].img_scale = (894, 448)\n",
    "cfg.data.val.pipeline[1].img_scale = (894, 448)\n",
    "cfg.data.test.pipeline[1].img_scale = (894, 448)\n",
    "\n",
    "cfg.optimizer.lr = 0.001\n",
    "cfg.optimizer.weight_decay = 0.0001\n",
    "\n",
    "cfg.classes = (\"lane\", \"crack\", \"pothole\")\n",
    "cfg.data.train.classes = cfg.classes\n",
    "cfg.data.val.classes = cfg.classes\n",
    "cfg.data.test.classes = cfg.classes\n",
    "\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = \"cuda\"\n",
    "\n",
    "cfg.work_dir = CONFIGS_DIR\n",
    "\n",
    "if os.path.exists(MRCNN_USER_CONFIG_PTH):\n",
    "    os.remove(MRCNN_USER_CONFIG_PTH)\n",
    "cfg.dump(MRCNN_USER_CONFIG_PTH)\n",
    "\n",
    "user_config = Config.fromfile(MRCNN_USER_CONFIG_PTH)\n",
    "print(user_config.pretty_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:44:40.876024Z",
     "end_time": "2023-04-25T16:44:41.712800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Создание модели**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.81s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(user_config.model)\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:44:41.713800Z",
     "end_time": "2023-04-25T16:44:48.162762Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Обучение модели**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# model.with_cp = True\n",
    "# model.fp16_enabled = True\n",
    "if not os.path.exists(CONFIGS_DIR + \"epoch_12.pth\"):\n",
    "    train_detector(model, datasets[0], cfg, distributed=False, validate=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T20:35:54.395685Z",
     "end_time": "2023-04-25T20:35:57.071930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
